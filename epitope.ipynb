{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc.single_pred import Epitope\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, f1_score, average_precision_score, precision_score, recall_score, accuracy_score\n",
    "from copy import deepcopy\n",
    "torch.manual_seed(1)\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from tdc.multi_pred import AntibodyAff\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.distributions import Categorical, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = AntibodyAff(name = 'Protein_SAbDab')\n",
    "# split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data =  Epitope(name = 'IEDB_Jespersen')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = split['train']\n",
    "valid_data = split['valid']\n",
    "test_data = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_protlists(data):\n",
    "\n",
    "#     protlists = list()\n",
    "#     temp_dict = data.to_dict(\"records\")\n",
    "#     for record in temp_dict:\n",
    "#         protlist = defaultdict(list)\n",
    "#         antigen = record['Antigen_ID']\n",
    "#         seq = record['Antigen']\n",
    "#         desc = ''\n",
    "#         protlist[antigen].append(desc)\n",
    "#         protlist[antigen].append(seq)\n",
    "\n",
    "#         protlists.append(protlist)\n",
    "        \n",
    "#     return protlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34350"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = train_data['Antigen'].tolist()\n",
    "maxlen = max([len(A) for A in lst])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 'Antigen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2vocab(data):\n",
    "\tlength = len(data)\n",
    "\tvocab_set = set()\n",
    "\ttotal_length, positive_num = 0, 0\n",
    "\tfor i in range(length):\n",
    "\t\tantigen = data[X][i]\n",
    "\t\tvocab_set = vocab_set.union(set(antigen))\n",
    "\t\tY = data['Y'][i]\n",
    "\t\tassert len(antigen) > max(Y)\n",
    "\t\ttotal_length += len(antigen)\n",
    "\t\tpositive_num += len(Y)\n",
    "\treturn vocab_set, positive_num / total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, train_positive_ratio = data2vocab(train_data)\n",
    "valid_vocab, valid_positive_ratio = data2vocab(valid_data)\n",
    "test_vocab, test_positive_ratio = data2vocab(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = train_vocab.union(valid_vocab)\n",
    "vocab_set = vocab_set.union(test_vocab)\n",
    "vocab_lst = list(vocab_set)\n",
    "# logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(idx, length):\n",
    "\tlst = [0 for i in range(length)]\n",
    "\tlst[idx] = 1\n",
    "\treturn lst \n",
    "\n",
    "def zerohot(length):\n",
    "\treturn [0 for i in range(length)]\n",
    "\n",
    "# what is the maxlength here\n",
    "def standardize_data(data, vocab_lst, maxlength = 300):\n",
    "\tlength = len(data)\n",
    "\tstandard_data = []\n",
    "\tfor i in range(length):\n",
    "\t\tantigen = data[X][i]\n",
    "\t\tY = data['Y'][i] \n",
    "\t\tsequence = [onehot(vocab_lst.index(s), len(vocab_lst)) for s in antigen] \n",
    "\t\tlabels = [0 for i in range(len(antigen))]\n",
    "\t\tmask = [True for i in range(len(labels))] # labels and mask have the same length\n",
    "\t\tsequence += (maxlength-len(sequence)) * [zerohot(len(vocab_lst))] #pad to consistent length\n",
    "\t\tlabels += (maxlength-len(labels)) * [0] \n",
    "\t\tmask += (maxlength-len(mask)) * [False] # pad to maxlength\n",
    "\t\tfor y in Y:\n",
    "\t\t\tlabels[y] = 1 \t\t\n",
    "\t\tsequence, labels, mask = sequence[:maxlength], labels[:maxlength], mask[:maxlength]\n",
    "\t\tsequence, labels, mask = torch.FloatTensor(sequence), torch.FloatTensor(labels), torch.BoolTensor(mask) \n",
    "\t\t# print(sequence.shape, labels.shape, mask.shape)\n",
    "        # sequence is 2D, labels and mask are 1D\n",
    "\t\tstandard_data.append((sequence, labels, mask))\n",
    "\treturn standard_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standardize_data2(data, vocab_lst):\n",
    "# \tlength = len(data)\n",
    "# \tstandard_data = []\n",
    "# \tfor i in range(length):\n",
    "# \t\tantigen = data[X][i]\n",
    "# \t\tY = data['Y'][i] \n",
    "# \t\tsequence = [onehot(vocab_lst.index(s), len(vocab_lst)) for s in antigen] \n",
    "# \t\tlabels = [0 for i in range(len(antigen))]\n",
    "# \t\tmask = [True for i in range(len(labels))] # labels and mask have the same length\n",
    "# # \t\tsequence += (maxlength-len(sequence)) * [zerohot(len(vocab_lst))] #pad to consistent length\n",
    "# # \t\tlabels += (maxlength-len(labels)) * [0] \n",
    "# # \t\tmask += (maxlength-len(mask)) * [False] # pad to maxlength\n",
    "# \t\tfor y in Y:\n",
    "# \t\t\tlabels[y] = 1 \t\t\n",
    "# # \t\tsequence, labels, mask = sequence[:maxlength], labels[:maxlength], mask[:maxlength]\n",
    "# \t\tsequence, labels, mask = torch.FloatTensor(sequence), torch.FloatTensor(labels), torch.BoolTensor(mask) \n",
    "# \t\t# print(sequence.shape, labels.shape, mask.shape)\n",
    "#         # sequence is 2D, labels and mask are 1D\n",
    "# \t\tstandard_data.append((sequence, labels, mask))\n",
    "# \treturn standard_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_stand2 = standardize_data2(train_data, vocab_lst)\n",
    "# valid_data_stand2 = standardize_data2(valid_data, vocab_lst)\n",
    "# test_data_stand2 = standardize_data2(test_data, vocab_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_stand = standardize_data(train_data, vocab_lst)\n",
    "valid_data_stand = standardize_data(valid_data, vocab_lst)\n",
    "test_data_stand = standardize_data(test_data, vocab_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "\tdef __init__(self, data):\n",
    "\t\tself.sequences = [i[0] for i in data]\n",
    "\t\tself.labels = [i[1] for i in data]\n",
    "\t\tself.mask = [i[2] for i in data] \n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.sequences[index], self.labels[index], self.mask[index]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset(train_data_stand)\n",
    "valid_set = dataset(valid_data_stand)\n",
    "test_set = dataset(test_data_stand)\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:00<00:00, 1440.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([3, 300, 24]) torch.Size([3, 300]) torch.Size([3, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sequence, labels, mask in tqdm(train_loader):\n",
    "    \n",
    "    print(sequence.shape, labels.shape, mask.shape)\n",
    "# for batch, (x,y,z) in enumerate(train_loader):\n",
    "#         print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([2, 4, 3]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "i = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "o = embedding(i)\n",
    "i.shape, o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_stand[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(label_lst, predict_lst, name):\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label_lst, predict_lst, )\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2493,  0.2576, -0.0780], requires_grad=True),\n",
       " tensor([1., 0., 0.]),\n",
       " tensor(0.7702, grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " None)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCEWithLogitsLoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(input, target)\n",
    "input, target, output, output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.5674, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n[0] + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.1693, -1.0862,  0.2509, -2.3874]]),\n",
       " torch.Size([1, 4]),\n",
       " tensor([1.2722]),\n",
       " torch.Size([1]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.FloatTensor([output.item()])\n",
    "c, c.shape, output, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.unsqueeze(output, 0)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1693, -1.0862,  0.2509, -2.3874,  1.2722]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cat((c,output), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25]))\n",
    "m.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(4, 1)\n",
    "c = torch.randn(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3045],\n",
       "         [-0.1741],\n",
       "         [ 0.1884],\n",
       "         [-1.2225]]),\n",
       " torch.Size([4, 1]),\n",
       " tensor([[-1.1693, -1.0862,  0.2509, -2.3874]]),\n",
       " torch.Size([1, 4]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, b.shape, c, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3561, -0.3308,  0.0764, -0.7271],\n",
       "         [-0.2035, -0.1891,  0.0437, -0.4156],\n",
       "         [ 0.2203,  0.2046, -0.0473,  0.4498],\n",
       "         [-1.4295, -1.3279,  0.3067, -2.9186]]),\n",
       " tensor([-1.3376, -0.7645,  0.8275, -5.3694]))"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.mul(b, c).mul(-1)\n",
    "m = torch.sum(loss, dim=-1)\n",
    "loss, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3376)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = torch.sum(torch.mul(b, c).mul(-1), -1)\n",
    "n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3]]), tensor([0, 1, 2, 3]), torch.Size([4]), tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3]]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([[0, 1], [2, 3]])\n",
    "b2 = torch.reshape(b, (-1,))\n",
    "b3 = torch.unsqueeze(b2, 1)\n",
    "b, b2, b2.shape, b3, b3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = []\n",
    "rewards.insert(0,2)\n",
    "rewards.insert(0,3)\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8064],\n",
       "        [-2.4553],\n",
       "        [    nan],\n",
       "        [    nan],\n",
       "        [-0.1831]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(5,1)\n",
    "torch.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, name, hidden_size, input_size, num_layers = 2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.name = name \n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size \n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,         # rnn hidden unit\n",
    "            num_layers=num_layers,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, 1)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()  \n",
    "        self.opt = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out)\n",
    "        out = out.squeeze(-1)\n",
    "        return out\n",
    "    \n",
    "    def learn(self, sequence, labels, mask):\n",
    "        prediction_lst = []\n",
    "        label_lst = []\n",
    "        prediction = self.forward(sequence)\n",
    "        pred = torch.sigmoid(prediction)\n",
    "        print(prediction, prediction.shape)\n",
    "#         print(pred, pred.shape)\n",
    "        print(labels)\n",
    "#         print(mask)\n",
    "        for pred, label, msk in zip(prediction, labels, mask):\n",
    "                num = sum(msk.tolist()) \n",
    "                pred = pred.tolist()[:num] \n",
    "                label = label.tolist()[:num] \n",
    "                label_lst.extend(label)\n",
    "                prediction_lst.extend(pred)\n",
    "#         print(prediction_lst)\n",
    "        sort_pred = deepcopy(prediction_lst)\n",
    "        sort_pred.sort() \n",
    "        threshold = sort_pred[int(len(sort_pred)*0.9)]\n",
    "#         print(threshold, type(threshold))\n",
    "#         print(type(prediction_lst))\n",
    "#         threshold = 0.5\n",
    "        float2binary = lambda x:0 if x<threshold else 1\n",
    "        binary_pred_lst = list(map(float2binary, prediction_lst))\n",
    "#         print(binary_pred_lst, len(binary_pred_lst))\n",
    "        \n",
    "#         print(\"size\", prediction.shape, labels.shape, mask.shape)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(size_average=True, weight = mask)  \n",
    "        \n",
    "        loss = criterion(prediction, labels)\n",
    "        print(loss)\n",
    "        self.opt.zero_grad() \n",
    "        loss.backward() \n",
    "        self.opt.step()\n",
    "        \n",
    "    def test(self, test_loader, name):\n",
    "        label_lst, prediction_lst = [], []\n",
    "        for sequence, labels, mask in test_loader:\n",
    "            prediction = self.forward(sequence)\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "#             print(prediction)\n",
    "            for pred, label, msk in zip(prediction, labels, mask):\n",
    "                num = sum(msk.tolist()) \n",
    "                pred = pred.tolist()[:num] \n",
    "                label = label.tolist()[:num] \n",
    "                label_lst.extend(label)\n",
    "                prediction_lst.extend(pred)\n",
    "#         print(prediction_lst)\n",
    "        sort_pred = deepcopy(prediction_lst)\n",
    "        sort_pred.sort() \n",
    "        threshold = sort_pred[int(len(sort_pred)*0.9)]\n",
    "        print(threshold, type(threshold))\n",
    "        print(type(prediction_lst))\n",
    "        float2binary = lambda x:0 if x<threshold else 1\n",
    "        binary_pred_lst = list(map(float2binary, prediction_lst))\n",
    "        plot(label_lst, prediction_lst, name)\n",
    "        print('roc_auc', roc_auc_score(label_lst, prediction_lst), \n",
    "    \t\t  'F1', f1_score(label_lst, binary_pred_lst), \n",
    "    \t\t  'prauc', average_precision_score(label_lst, binary_pred_lst))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0895, -0.0885, -0.0876,  ..., -0.0886, -0.0893, -0.0923],\n",
      "        [-0.0895, -0.0917, -0.0910,  ..., -0.0900, -0.0900, -0.0900],\n",
      "        [-0.0895, -0.0885, -0.0876,  ..., -0.0869, -0.0874, -0.0879],\n",
      "        ...,\n",
      "        [-0.0895, -0.0902, -0.0912,  ..., -0.0900, -0.0900, -0.0900],\n",
      "        [-0.0890, -0.0885, -0.0879,  ..., -0.0900, -0.0900, -0.0900],\n",
      "        [-0.0895, -0.0902, -0.0899,  ..., -0.0954, -0.0959, -0.0978]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.5078, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.0976, -0.1075, -0.1146,  ..., -0.1255, -0.1253, -0.1244],\n",
      "        [-0.0962, -0.1056, -0.1129,  ..., -0.1216, -0.1216, -0.1216],\n",
      "        [-0.0971, -0.1025, -0.1073,  ..., -0.1216, -0.1216, -0.1216],\n",
      "        ...,\n",
      "        [-0.0971, -0.1030, -0.1080,  ..., -0.1216, -0.1216, -0.1216],\n",
      "        [-0.0971, -0.1049, -0.1101,  ..., -0.1216, -0.1216, -0.1216],\n",
      "        [-0.0971, -0.1065, -0.1148,  ..., -0.1216, -0.1216, -0.1216]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.4670, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1037, -0.1169, -0.1251,  ..., -0.1538, -0.1538, -0.1538],\n",
      "        [-0.1047, -0.1213, -0.1320,  ..., -0.1514, -0.1523, -0.1540],\n",
      "        [-0.1047, -0.1213, -0.1356,  ..., -0.1592, -0.1616, -0.1603],\n",
      "        ...,\n",
      "        [-0.1047, -0.1185, -0.1289,  ..., -0.1540, -0.1520, -0.1515],\n",
      "        [-0.1047, -0.1194, -0.1316,  ..., -0.1538, -0.1538, -0.1538],\n",
      "        [-0.1047, -0.1186, -0.1286,  ..., -0.1628, -0.1636, -0.1657]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.5273, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1130, -0.1361, -0.1550,  ..., -0.1875, -0.1875, -0.1875],\n",
      "        [-0.1123, -0.1326, -0.1505,  ..., -0.1875, -0.1875, -0.1875],\n",
      "        [-0.1123, -0.1326, -0.1484,  ..., -0.1953, -0.1948, -0.1935],\n",
      "        ...,\n",
      "        [-0.1123, -0.1346, -0.1526,  ..., -0.1920, -0.1908, -0.1895],\n",
      "        [-0.1110, -0.1298, -0.1447,  ..., -0.1875, -0.1875, -0.1875],\n",
      "        [-0.1123, -0.1315, -0.1488,  ..., -0.1965, -0.1954, -0.1942]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.5219, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1201, -0.1517, -0.1747,  ..., -0.2311, -0.2323, -0.2309],\n",
      "        [-0.1201, -0.1499, -0.1748,  ..., -0.2335, -0.2314, -0.2281],\n",
      "        [-0.1201, -0.1477, -0.1708,  ..., -0.2242, -0.2242, -0.2242],\n",
      "        ...,\n",
      "        [-0.1201, -0.1477, -0.1706,  ..., -0.2242, -0.2242, -0.2242],\n",
      "        [-0.1183, -0.1479, -0.1728,  ..., -0.2260, -0.2240, -0.2243],\n",
      "        [-0.1201, -0.1496, -0.1763,  ..., -0.2319, -0.2306, -0.2293]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.5300, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1280, -0.1625, -0.1921,  ..., -0.2716, -0.2736, -0.2747],\n",
      "        [-0.1285, -0.1668, -0.1969,  ..., -0.2652, -0.2652, -0.2652],\n",
      "        [-0.1273, -0.1629, -0.1905,  ..., -0.2723, -0.2739, -0.2739],\n",
      "        ...,\n",
      "        [-0.1302, -0.1662, -0.1949,  ..., -0.2652, -0.2652, -0.2652],\n",
      "        [-0.1280, -0.1676, -0.1978,  ..., -0.2778, -0.2778, -0.2783],\n",
      "        [-0.1280, -0.1625, -0.1951,  ..., -0.2736, -0.2753, -0.2774]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.4856, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1360, -0.1808, -0.2204,  ..., -0.3175, -0.3182, -0.3190],\n",
      "        [-0.1360, -0.1842, -0.2220,  ..., -0.3128, -0.3128, -0.3128],\n",
      "        [-0.1360, -0.1787, -0.2191,  ..., -0.3128, -0.3128, -0.3128],\n",
      "        ...,\n",
      "        [-0.1360, -0.1787, -0.2191,  ..., -0.3128, -0.3128, -0.3128],\n",
      "        [-0.1360, -0.1842, -0.2222,  ..., -0.3128, -0.3128, -0.3128],\n",
      "        [-0.1360, -0.1842, -0.2222,  ..., -0.3128, -0.3128, -0.3128]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.4503, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1441, -0.1960, -0.2403,  ..., -0.3699, -0.3699, -0.3699],\n",
      "        [-0.1441, -0.1987, -0.2479,  ..., -0.3894, -0.3903, -0.3889],\n",
      "        [-0.1441, -0.1960, -0.2402,  ..., -0.3900, -0.3881, -0.3898],\n",
      "        ...,\n",
      "        [-0.1441, -0.1978, -0.2433,  ..., -0.3699, -0.3699, -0.3699],\n",
      "        [-0.1441, -0.2015, -0.2498,  ..., -0.3851, -0.3900, -0.3897],\n",
      "        [-0.1441, -0.2015, -0.2494,  ..., -0.3892, -0.3931, -0.3920]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.4337, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1527, -0.2143, -0.2687,  ..., -0.4678, -0.4730, -0.4737],\n",
      "        [-0.1525, -0.2136, -0.2693,  ..., -0.4640, -0.4633, -0.4642],\n",
      "        [-0.1525, -0.2156, -0.2673,  ..., -0.4414, -0.4414, -0.4414],\n",
      "        ...,\n",
      "        [-0.1525, -0.2198, -0.2823,  ..., -0.4723, -0.4772, -0.4778],\n",
      "        [-0.1491, -0.2121, -0.2684,  ..., -0.4414, -0.4414, -0.4414],\n",
      "        [-0.1525, -0.2172, -0.2747,  ..., -0.4683, -0.4677, -0.4654]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.4238, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1610, -0.2320, -0.2989,  ..., -0.5340, -0.5340, -0.5340],\n",
      "        [-0.1610, -0.2321, -0.3028,  ..., -0.5698, -0.5717, -0.5703],\n",
      "        [-0.1610, -0.2288, -0.2924,  ..., -0.5814, -0.5801, -0.5810],\n",
      "        ...,\n",
      "        [-0.1642, -0.2368, -0.3060,  ..., -0.5677, -0.5665, -0.5655],\n",
      "        [-0.1610, -0.2362, -0.3057,  ..., -0.5672, -0.5672, -0.5661],\n",
      "        [-0.1610, -0.2362, -0.3037,  ..., -0.5644, -0.5684, -0.5730]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "tensor(0.3775, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1699, -0.2560, -0.3378,  ..., -0.7323, -0.7321, -0.7301],\n",
      "        [-0.1699, -0.2483, -0.3288,  ..., -0.7206, -0.7170, -0.7139],\n",
      "        [-0.1699, -0.2532, -0.3361,  ..., -0.7090, -0.7095, -0.7071],\n",
      "        ...,\n",
      "        [-0.1699, -0.2564, -0.3404,  ..., -0.6622, -0.6620, -0.6619],\n",
      "        [-0.1699, -0.2530, -0.3329,  ..., -0.7333, -0.7329, -0.7318],\n",
      "        [-0.1686, -0.2506, -0.3341,  ..., -0.7145, -0.7116, -0.7154]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.4018, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1789, -0.2734, -0.3669,  ..., -0.9335, -0.9386, -0.9426],\n",
      "        [-0.1789, -0.2757, -0.3712,  ..., -0.9397, -0.9425, -0.9461],\n",
      "        [-0.1789, -0.2766, -0.3704,  ..., -0.9798, -0.9744, -0.9685],\n",
      "        ...,\n",
      "        [-0.1789, -0.2779, -0.3809,  ..., -0.9250, -0.9238, -0.9287],\n",
      "        [-0.1789, -0.2740, -0.3702,  ..., -0.9332, -0.9375, -0.9419],\n",
      "        [-0.1789, -0.2734, -0.3658,  ..., -0.9475, -0.9462, -0.9474]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.3254, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1883, -0.2967, -0.4120,  ..., -1.2728, -1.2718, -1.2697],\n",
      "        [-0.1891, -0.2994, -0.4130,  ..., -1.2938, -1.2921, -1.2903],\n",
      "        [-0.1883, -0.3009, -0.4178,  ..., -1.2751, -1.2806, -1.2848],\n",
      "        ...,\n",
      "        [-0.1883, -0.3003, -0.4121,  ..., -1.2542, -1.2552, -1.2559],\n",
      "        [-0.1883, -0.3009, -0.4140,  ..., -1.2744, -1.2744, -1.2746],\n",
      "        [-0.1883, -0.2970, -0.4074,  ..., -1.3398, -1.3391, -1.3324]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.2739, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor([[-0.1980, -0.3227, -0.4556,  ..., -1.7673, -1.7767, -1.7786],\n",
      "        [-0.1980, -0.3255, -0.4680,  ..., -1.7332, -1.7299, -1.7305],\n",
      "        [-0.1980, -0.3206, -0.4550,  ..., -1.8380, -1.8352, -1.8309],\n",
      "        ...,\n",
      "        [-0.1980, -0.3213, -0.4511,  ..., -1.7588, -1.7609, -1.7603],\n",
      "        [-0.1980, -0.3203, -0.4506,  ..., -1.7936, -1.7919, -1.7889],\n",
      "        [-0.1946, -0.3173, -0.4473,  ..., -1.5659, -1.5659, -1.5659]],\n",
      "       grad_fn=<SqueezeBackward1>) torch.Size([16, 300])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor(0.1993, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-81cd12872556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         print(sequence.shape, labels.shape, mask.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-206-22d614c2332d>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, sequence, labels, mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprediction_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlabel_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-206-22d614c2332d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# h_n shape (n_layers, batch, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# h_c shape (n_layers, batch, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# None represents zero initial hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# choose r_out at the last time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 559\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    560\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RNN(name = 'Epitope', hidden_size=100, input_size=len(vocab_lst))\n",
    "epoch = 10\n",
    "for ep in range(epoch):\n",
    "    for sequence, labels, mask in train_loader:\n",
    "#         print(sequence.shape, labels.shape, mask.shape)\n",
    "        model.learn(sequence, labels, mask)\n",
    "    model.test(test_loader, name = model.name + '_' + str(ep) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
