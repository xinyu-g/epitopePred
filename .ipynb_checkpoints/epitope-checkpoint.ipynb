{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc.single_pred import Epitope\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, f1_score, average_precision_score, precision_score, recall_score, accuracy_score\n",
    "from copy import deepcopy\n",
    "torch.manual_seed(1)\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from tdc.multi_pred import AntibodyAff\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = AntibodyAff(name = 'Protein_SAbDab')\n",
    "# split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data =  Epitope(name = 'IEDB_Jespersen')\n",
    "split = data.get_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = split['train']\n",
    "valid_data = split['valid']\n",
    "test_data = split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_protlists(data):\n",
    "\n",
    "#     protlists = list()\n",
    "#     temp_dict = data.to_dict(\"records\")\n",
    "#     for record in temp_dict:\n",
    "#         protlist = defaultdict(list)\n",
    "#         antigen = record['Antigen_ID']\n",
    "#         seq = record['Antigen']\n",
    "#         desc = ''\n",
    "#         protlist[antigen].append(desc)\n",
    "#         protlist[antigen].append(seq)\n",
    "\n",
    "#         protlists.append(protlist)\n",
    "        \n",
    "#     return protlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34350"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = train_data['Antigen'].tolist()\n",
    "maxlen = max([len(A) for A in lst])\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 'Antigen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2vocab(data):\n",
    "\tlength = len(data)\n",
    "\tvocab_set = set()\n",
    "\ttotal_length, positive_num = 0, 0\n",
    "\tfor i in range(length):\n",
    "\t\tantigen = data[X][i]\n",
    "\t\tvocab_set = vocab_set.union(set(antigen))\n",
    "\t\tY = data['Y'][i]\n",
    "\t\tassert len(antigen) > max(Y)\n",
    "\t\ttotal_length += len(antigen)\n",
    "\t\tpositive_num += len(Y)\n",
    "\treturn vocab_set, positive_num / total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab, train_positive_ratio = data2vocab(train_data)\n",
    "valid_vocab, valid_positive_ratio = data2vocab(valid_data)\n",
    "test_vocab, test_positive_ratio = data2vocab(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = train_vocab.union(valid_vocab)\n",
    "vocab_set = vocab_set.union(test_vocab)\n",
    "vocab_lst = list(vocab_set)\n",
    "# logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(idx, length):\n",
    "\tlst = [0 for i in range(length)]\n",
    "\tlst[idx] = 1\n",
    "\treturn lst \n",
    "\n",
    "def zerohot(length):\n",
    "\treturn [0 for i in range(length)]\n",
    "\n",
    "# what is the maxlength here\n",
    "def standardize_data(data, vocab_lst, maxlength = 300):\n",
    "\tlength = len(data)\n",
    "\tstandard_data = []\n",
    "\tfor i in range(length):\n",
    "\t\tantigen = data[X][i]\n",
    "\t\tY = data['Y'][i] \n",
    "\t\tsequence = [onehot(vocab_lst.index(s), len(vocab_lst)) for s in antigen] \n",
    "\t\tlabels = [0 for i in range(len(antigen))]\n",
    "\t\tmask = [True for i in range(len(labels))] # labels and mask have the same length\n",
    "\t\tsequence += (maxlength-len(sequence)) * [zerohot(len(vocab_lst))] #pad to consistent length\n",
    "\t\tlabels += (maxlength-len(labels)) * [0] \n",
    "\t\tmask += (maxlength-len(mask)) * [False] # pad to maxlength\n",
    "\t\tfor y in Y:\n",
    "\t\t\tlabels[y] = 1 \t\t\n",
    "\t\tsequence, labels, mask = sequence[:maxlength], labels[:maxlength], mask[:maxlength]\n",
    "\t\tsequence, labels, mask = torch.FloatTensor(sequence), torch.FloatTensor(labels), torch.BoolTensor(mask) \n",
    "\t\t# print(sequence.shape, labels.shape, mask.shape)\n",
    "        # sequence is 2D, labels and mask are 1D\n",
    "\t\tstandard_data.append((sequence, labels, mask))\n",
    "\treturn standard_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standardize_data2(data, vocab_lst):\n",
    "# \tlength = len(data)\n",
    "# \tstandard_data = []\n",
    "# \tfor i in range(length):\n",
    "# \t\tantigen = data[X][i]\n",
    "# \t\tY = data['Y'][i] \n",
    "# \t\tsequence = [onehot(vocab_lst.index(s), len(vocab_lst)) for s in antigen] \n",
    "# \t\tlabels = [0 for i in range(len(antigen))]\n",
    "# \t\tmask = [True for i in range(len(labels))] # labels and mask have the same length\n",
    "# # \t\tsequence += (maxlength-len(sequence)) * [zerohot(len(vocab_lst))] #pad to consistent length\n",
    "# # \t\tlabels += (maxlength-len(labels)) * [0] \n",
    "# # \t\tmask += (maxlength-len(mask)) * [False] # pad to maxlength\n",
    "# \t\tfor y in Y:\n",
    "# \t\t\tlabels[y] = 1 \t\t\n",
    "# # \t\tsequence, labels, mask = sequence[:maxlength], labels[:maxlength], mask[:maxlength]\n",
    "# \t\tsequence, labels, mask = torch.FloatTensor(sequence), torch.FloatTensor(labels), torch.BoolTensor(mask) \n",
    "# \t\t# print(sequence.shape, labels.shape, mask.shape)\n",
    "#         # sequence is 2D, labels and mask are 1D\n",
    "# \t\tstandard_data.append((sequence, labels, mask))\n",
    "# \treturn standard_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_stand2 = standardize_data2(train_data, vocab_lst)\n",
    "# valid_data_stand2 = standardize_data2(valid_data, vocab_lst)\n",
    "# test_data_stand2 = standardize_data2(test_data, vocab_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_stand = standardize_data(train_data, vocab_lst)\n",
    "valid_data_stand = standardize_data(valid_data, vocab_lst)\n",
    "test_data_stand = standardize_data(test_data, vocab_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "\tdef __init__(self, data):\n",
    "\t\tself.sequences = [i[0] for i in data]\n",
    "\t\tself.labels = [i[1] for i in data]\n",
    "\t\tself.mask = [i[2] for i in data] \n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn self.sequences[index], self.labels[index], self.mask[index]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset(train_data_stand)\n",
    "valid_set = dataset(valid_data_stand)\n",
    "test_set = dataset(test_data_stand)\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:00<00:00, 1440.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([16, 300, 24]) torch.Size([16, 300]) torch.Size([16, 300])\n",
      "torch.Size([3, 300, 24]) torch.Size([3, 300]) torch.Size([3, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for sequence, labels, mask in tqdm(train_loader):\n",
    "    \n",
    "    print(sequence.shape, labels.shape, mask.shape)\n",
    "# for batch, (x,y,z) in enumerate(train_loader):\n",
    "#         print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([2, 4, 3]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(10, 3)\n",
    "i = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "o = embedding(i)\n",
    "i.shape, o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data_stand[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(label_lst, predict_lst, name):\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label_lst, predict_lst, )\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, name, hidden_size, input_size, num_layers = 2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.name = name \n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size \n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,         # rnn hidden unit\n",
    "            num_layers=num_layers,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, 1)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss()  \n",
    "        self.opt = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out)\n",
    "        out = out.squeeze(-1)\n",
    "        return out\n",
    "    \n",
    "    def learn(self, sequence, labels, mask):\n",
    "        prediction = self.forward(sequence)\n",
    "#         pred = torch.sigmoid(prediction)\n",
    "#         float2binary = lambda x:0 if x<0.05 else 1\n",
    "#         pred_bin = list(map(float2binary, pred.tolist()))\n",
    "#         print(pred_bin)\n",
    "#         print(prediction)\n",
    "        # print(\"size\", prediction.shape, labels.shape, mask.shape)\n",
    "        criterion = torch.nn.BCEWithLogitsLoss(size_average=True, weight = mask)  \n",
    "        loss = criterion(prediction, labels)\n",
    "        self.opt.zero_grad() \n",
    "        loss.backward() \n",
    "        self.opt.step()\n",
    "        \n",
    "    def test(self, test_loader, name):\n",
    "        label_lst, prediction_lst = [], []\n",
    "        for sequence, labels, mask in test_loader:\n",
    "            prediction = self.forward(sequence)\n",
    "            prediction = torch.sigmoid(prediction)\n",
    "#             print(prediction)\n",
    "            for pred, label, msk in zip(prediction, labels, mask):\n",
    "                num = sum(msk.tolist()) \n",
    "                pred = pred.tolist()[:num] \n",
    "                label = label.tolist()[:num] \n",
    "                label_lst.extend(label)\n",
    "                prediction_lst.extend(pred)\n",
    "#         print(prediction_lst)\n",
    "        sort_pred = deepcopy(prediction_lst)\n",
    "        sort_pred.sort() \n",
    "        threshold = sort_pred[int(len(sort_pred)*0.9)]\n",
    "        print(threshold, type(threshold))\n",
    "        print(prediction_lst)\n",
    "        float2binary = lambda x:0 if x<threshold else 1\n",
    "        binary_pred_lst = list(map(float2binary, prediction_lst))\n",
    "        plot(label_lst, prediction_lst, name)\n",
    "        print('roc_auc', roc_auc_score(label_lst, prediction_lst), \n",
    "    \t\t  'F1', f1_score(label_lst, binary_pred_lst), \n",
    "    \t\t  'prauc', average_precision_score(label_lst, binary_pred_lst))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc 0.5240805985458111 F1 0.06791946308724832 prauc 0.04200020204682281\n"
     ]
    }
   ],
   "source": [
    "model = RNN(name = 'Epitope', hidden_size=100, input_size=len(vocab_lst))\n",
    "epoch = 10\n",
    "for ep in range(epoch):\n",
    "    for sequence, labels, mask in train_loader:\n",
    "#         print(sequence.shape, labels.shape, mask.shape)\n",
    "        model.learn(sequence, labels, mask)\n",
    "    model.test(test_loader, name = model.name + '_' + str(ep) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
